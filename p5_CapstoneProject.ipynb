{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3ff0632e-0869-4c94-94b3-4112d6127afc",
   "metadata": {},
   "source": [
    "# P5 - Learning\n",
    "\n",
    "This project give you experience with Learning topics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dc90da23-0018-4e06-8dd6-e49ff6dce632",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import model_selection\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, make_scorer\n",
    "\n",
    "from sklearn.feature_selection import SelectPercentile\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn import svm\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import numpy as np\n",
    "np.random.seed(5550)\n",
    "\n",
    "import otter\n",
    "grader = otter.Notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4552aa7d-504d-462c-97fb-3cc75cbc8dc7",
   "metadata": {},
   "source": [
    "# Problem: Classification - Music Hits \n",
    "\n",
    "For this problem, you will work to classify a song’s popularity. Specifically, you will develop methods to predict whether a song will make the Top10 of Billboard’s Hot 100 Chart. The data set consists of song from the Top10 of Billboard’s Hot 100 Chart from 1990-2010 along with a sampling of other songs that did not make the list.  \n",
    "\n",
    "The data source is adapted from one used in a MIT 15.071 course. The data set was created by scraping Billboard’s Hot 100, other songs on Billboard, and using the EchoNest API, now a part of Spotify, to get song information.\n",
    "\n",
    "The variables included in the data set include several description of the song and artist (including song title and id numbers), the year the song was released. Additionally, several variables describe the song attributes: time signature, loudness, tempo, key, energy pitch, and timbre (measured of different sections of the song). The last variable is binary indicated whether the song was in the Top10 or not.\n",
    "\n",
    "You will use the variables of the song attributes to predict whether the song will be popular or not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dadc441f-75ca-4c5e-94ec-d4dd63ffc197",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q1 - Load and understand the data \n",
    "\n",
    "Load in the `music` data. \n",
    "\n",
    "You should not use the `year`, `artistname`, `artistID`, `songtitle` or `songID` in the prediction.  \n",
    "Additionally, remove any variables that are the confidence of another variable, e.g., `timesignature_confidence`, `temp_confidence`. \n",
    "\n",
    "\n",
    "Create a input feature matrix, `Xm` and label vector `ym` that you will use to create your classifiers. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1f006bea-1370-43cb-b2ad-7051578250d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>timesignature</th>\n",
       "      <th>loudness</th>\n",
       "      <th>tempo</th>\n",
       "      <th>key</th>\n",
       "      <th>energy</th>\n",
       "      <th>pitch</th>\n",
       "      <th>timbre_0_min</th>\n",
       "      <th>timbre_0_max</th>\n",
       "      <th>timbre_1_min</th>\n",
       "      <th>timbre_1_max</th>\n",
       "      <th>...</th>\n",
       "      <th>timbre_7_min</th>\n",
       "      <th>timbre_7_max</th>\n",
       "      <th>timbre_8_min</th>\n",
       "      <th>timbre_8_max</th>\n",
       "      <th>timbre_9_min</th>\n",
       "      <th>timbre_9_max</th>\n",
       "      <th>timbre_10_min</th>\n",
       "      <th>timbre_10_max</th>\n",
       "      <th>timbre_11_min</th>\n",
       "      <th>timbre_11_max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>-4.262</td>\n",
       "      <td>91.525</td>\n",
       "      <td>11</td>\n",
       "      <td>0.966656</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.002</td>\n",
       "      <td>57.342</td>\n",
       "      <td>-6.496</td>\n",
       "      <td>171.093</td>\n",
       "      <td>...</td>\n",
       "      <td>-71.127</td>\n",
       "      <td>82.475</td>\n",
       "      <td>-52.025</td>\n",
       "      <td>39.116</td>\n",
       "      <td>-35.368</td>\n",
       "      <td>71.642</td>\n",
       "      <td>-126.440</td>\n",
       "      <td>18.658</td>\n",
       "      <td>-44.770</td>\n",
       "      <td>25.989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>-4.051</td>\n",
       "      <td>140.048</td>\n",
       "      <td>10</td>\n",
       "      <td>0.984710</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.000</td>\n",
       "      <td>57.414</td>\n",
       "      <td>-37.351</td>\n",
       "      <td>171.130</td>\n",
       "      <td>...</td>\n",
       "      <td>-65.807</td>\n",
       "      <td>106.918</td>\n",
       "      <td>-61.320</td>\n",
       "      <td>35.378</td>\n",
       "      <td>-81.928</td>\n",
       "      <td>74.574</td>\n",
       "      <td>-103.808</td>\n",
       "      <td>121.935</td>\n",
       "      <td>-38.892</td>\n",
       "      <td>22.513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>-3.571</td>\n",
       "      <td>160.512</td>\n",
       "      <td>2</td>\n",
       "      <td>0.989900</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.003</td>\n",
       "      <td>57.422</td>\n",
       "      <td>-17.222</td>\n",
       "      <td>171.060</td>\n",
       "      <td>...</td>\n",
       "      <td>-67.433</td>\n",
       "      <td>80.621</td>\n",
       "      <td>-59.773</td>\n",
       "      <td>45.979</td>\n",
       "      <td>-46.293</td>\n",
       "      <td>59.904</td>\n",
       "      <td>-108.313</td>\n",
       "      <td>33.300</td>\n",
       "      <td>-43.733</td>\n",
       "      <td>25.744</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>-3.815</td>\n",
       "      <td>97.525</td>\n",
       "      <td>1</td>\n",
       "      <td>0.939207</td>\n",
       "      <td>0.013</td>\n",
       "      <td>0.000</td>\n",
       "      <td>57.765</td>\n",
       "      <td>-32.083</td>\n",
       "      <td>220.895</td>\n",
       "      <td>...</td>\n",
       "      <td>-63.667</td>\n",
       "      <td>96.675</td>\n",
       "      <td>-78.660</td>\n",
       "      <td>41.088</td>\n",
       "      <td>-49.194</td>\n",
       "      <td>95.440</td>\n",
       "      <td>-102.676</td>\n",
       "      <td>46.422</td>\n",
       "      <td>-59.439</td>\n",
       "      <td>37.082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>-6.891</td>\n",
       "      <td>80.009</td>\n",
       "      <td>7</td>\n",
       "      <td>0.977862</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.057</td>\n",
       "      <td>55.404</td>\n",
       "      <td>-6.627</td>\n",
       "      <td>216.684</td>\n",
       "      <td>...</td>\n",
       "      <td>-57.084</td>\n",
       "      <td>77.725</td>\n",
       "      <td>-115.062</td>\n",
       "      <td>49.312</td>\n",
       "      <td>-31.369</td>\n",
       "      <td>40.076</td>\n",
       "      <td>-179.702</td>\n",
       "      <td>18.520</td>\n",
       "      <td>-57.549</td>\n",
       "      <td>22.489</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   timesignature  loudness    tempo  key    energy  pitch  timbre_0_min   \n",
       "0              3    -4.262   91.525   11  0.966656  0.024         0.002  \\\n",
       "1              4    -4.051  140.048   10  0.984710  0.025         0.000   \n",
       "2              4    -3.571  160.512    2  0.989900  0.026         0.003   \n",
       "3              4    -3.815   97.525    1  0.939207  0.013         0.000   \n",
       "4              4    -6.891   80.009    7  0.977862  0.008         0.057   \n",
       "\n",
       "   timbre_0_max  timbre_1_min  timbre_1_max  ...  timbre_7_min  timbre_7_max   \n",
       "0        57.342        -6.496       171.093  ...       -71.127        82.475  \\\n",
       "1        57.414       -37.351       171.130  ...       -65.807       106.918   \n",
       "2        57.422       -17.222       171.060  ...       -67.433        80.621   \n",
       "3        57.765       -32.083       220.895  ...       -63.667        96.675   \n",
       "4        55.404        -6.627       216.684  ...       -57.084        77.725   \n",
       "\n",
       "   timbre_8_min  timbre_8_max  timbre_9_min  timbre_9_max  timbre_10_min   \n",
       "0       -52.025        39.116       -35.368        71.642       -126.440  \\\n",
       "1       -61.320        35.378       -81.928        74.574       -103.808   \n",
       "2       -59.773        45.979       -46.293        59.904       -108.313   \n",
       "3       -78.660        41.088       -49.194        95.440       -102.676   \n",
       "4      -115.062        49.312       -31.369        40.076       -179.702   \n",
       "\n",
       "   timbre_10_max  timbre_11_min  timbre_11_max  \n",
       "0         18.658        -44.770         25.989  \n",
       "1        121.935        -38.892         22.513  \n",
       "2         33.300        -43.733         25.744  \n",
       "3         46.422        -59.439         37.082  \n",
       "4         18.520        -57.549         22.489  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "music = pd.read_csv(\"music.csv\", encoding=\"ISO-8859-1\")\n",
    "\n",
    "columns_drop = [ #Dropping these\n",
    "    \"year\",\n",
    "    \"artistname\",\n",
    "    \"artistID\",\n",
    "    \"songtitle\",\n",
    "    \"songID\",\n",
    "    \"timesignature_confidence\",\n",
    "    \"tempo_confidence\",\n",
    "    \"key_confidence\"\n",
    "]\n",
    "\n",
    "Xm = music.drop(columns=columns_drop + [\"Top10\"])\n",
    "ym = music[\"Top10\"]\n",
    "\n",
    "Xm.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d934dfe9",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q1</pre></strong> passed! 🚀</p>"
      ],
      "text/plain": [
       "q1 results: All test cases passed!"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a99fa5-4449-4454-9ee3-528fd3b4093f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q2. Classify Top 10 Hits \n",
    "\n",
    "We want to report out the results of predicting the top-10 hits using KNN, Decision Trees, and SVMS.  \n",
    "\n",
    "You will perform grid search to select the best hyperparameters with cross-validation.  However, you may not use `GridSearchCV`.  Instead you must use `StratifiedKFold` and other methodologies shown in class. \n",
    "\n",
    "You will do an initial stratified split of your data into training+validation set with 80% of the data and a test set with 20% of the data (`random_state`=5).  Within the train+val data, use 10-fold stratified cross-validation with a `random_state` = 5 and `shuffle` = True. \n",
    "\n",
    "For each model, you will tune the hyper-parameters:    \n",
    "* KNN, number of neighbors = [5, 9, 13, 17] and weights = ['uniform', 'distance']\n",
    "* Decision Trees, maximum depth of the tree = [3, 5, 8, 12] and criterion of ['gini', 'entropy'], set the random_state = 5\n",
    "* SVM, use a rbf kernel with C = [0.01, 0.1, 1, 10] \n",
    "\n",
    "In addition, you will want to see which scaling methods seems to work best for this dataset and method: `StandardScaler` or `MinMaxScaler`. \n",
    "\n",
    "When selecting the best hyper-parameters, instead of using accuracy you will use the `f1_measure`.  \n",
    "\n",
    "Make sure to consider how to set up the training and evaluation of your models to avoid overfitting and data leakage. \n",
    "\n",
    "Report out the best hyperparameters selected. \n",
    "\n",
    "Retrain the best model on the train+val data and report the f1-measure on the test data set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "219ff8cf-701e-4c7b-b991-50f7da302f82",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "knn best hyperparams:   5 distance StandardScaler\n",
      "dt best hyperparams:    12 gini StandardScaler\n",
      "svm best hyperparams:   10 StandardScaler\n",
      "\n",
      "Best Performance\n",
      "  KNN:   0.4150943396226415\n",
      "  DT:    0.4200913242009132\n",
      "  SVM:   0.5278450363196125\n"
     ]
    }
   ],
   "source": [
    "#Helper function to evaluate models\n",
    "def evaluate_model(model, X, y, scaler=None):\n",
    "    f1_scores = []\n",
    "    for train_idx, val_idx in kf.split(X, y):\n",
    "        X_train, X_val = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train, y_val = y.iloc[train_idx], y.iloc[val_idx]\n",
    "        if scaler:\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_val = scaler.transform(X_val)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_val)\n",
    "        f1_scores.append(f1_score(y_val, y_pred))\n",
    "    return sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "#split data into train+val and test sets \n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
    "    Xm, ym, test_size=0.2, random_state=5, stratify=ym\n",
    ")\n",
    "\n",
    "#10-fold stratified cross-validation\n",
    "kf = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "#nneeded variables\n",
    "scalers = [StandardScaler(), MinMaxScaler()]\n",
    "scaler_names = [\"StandardScaler\", \"MinMaxScaler\"]\n",
    "knn_params = {\"n_neighbors\": [5, 9, 13, 17], \"weights\": [\"uniform\", \"distance\"]}\n",
    "dt_params = {\"max_depth\": [3, 5, 8, 12], \"criterion\": [\"gini\", \"entropy\"]}\n",
    "svm_params = {\"C\": [0.01, 0.1, 1, 10]}\n",
    "best_knn = {\"f1\": 0, \"params\": None, \"scaler\": None}\n",
    "best_dt = {\"f1\": 0, \"params\": None, \"scaler\": None}\n",
    "best_svm = {\"f1\": 0, \"params\": None, \"scaler\": None}\n",
    "\n",
    "#KNN\n",
    "for scaler, scaler_name in zip(scalers, scaler_names):\n",
    "    for n_neighbors in knn_params[\"n_neighbors\"]:\n",
    "        for weights in knn_params[\"weights\"]:\n",
    "            knn = KNeighborsClassifier(n_neighbors=n_neighbors, weights=weights)\n",
    "            f1 = evaluate_model(knn, X_train_val, y_train_val, scaler)\n",
    "            if f1 > best_knn[\"f1\"]:\n",
    "                best_knn = {\"f1\": f1, \"params\": (n_neighbors, weights), \"scaler\": scaler_name}\n",
    "\n",
    "#Decision Tree\n",
    "for scaler, scaler_name in zip(scalers, scaler_names):\n",
    "    for max_depth in dt_params[\"max_depth\"]:\n",
    "        for criterion in dt_params[\"criterion\"]:\n",
    "            dt = DecisionTreeClassifier(max_depth=max_depth, criterion=criterion, random_state=5)\n",
    "            f1 = evaluate_model(dt, X_train_val, y_train_val, scaler)\n",
    "            if f1 > best_dt[\"f1\"]:\n",
    "                best_dt = {\"f1\": f1, \"params\": (max_depth, criterion), \"scaler\": scaler_name}\n",
    "\n",
    "#SVM\n",
    "for scaler, scaler_name in zip(scalers, scaler_names):\n",
    "    for C in svm_params[\"C\"]:\n",
    "        svc = SVC(C=C, kernel=\"rbf\", random_state=5)\n",
    "        f1 = evaluate_model(svc, X_train_val, y_train_val, scaler)\n",
    "        if f1 > best_svm[\"f1\"]:\n",
    "            best_svm = {\"f1\": f1, \"params\": C, \"scaler\": scaler_name}\n",
    "\n",
    "# Report best hyperparameters\n",
    "knn_bestNbrs, knn_bestWt = best_knn[\"params\"]\n",
    "knn_bestScaling = best_knn[\"scaler\"]\n",
    "dt_bestMaxDepth, dt_bestCrit = best_dt[\"params\"]\n",
    "dt_bestScaling = best_dt[\"scaler\"]\n",
    "svm_bestC = best_svm[\"params\"]\n",
    "svm_bestScaling = best_svm[\"scaler\"]\n",
    "\n",
    "#Retrain models with best hyperparameters on train+val and evaluate on test\n",
    "scalers_dict = {\"StandardScaler\": StandardScaler(), \"MinMaxScaler\": MinMaxScaler()}\n",
    "\n",
    "#KNN\n",
    "scaler = scalers_dict[knn_bestScaling]\n",
    "scaler.fit(X_train_val)\n",
    "X_train_val_scaled = scaler.transform(X_train_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "knn = KNeighborsClassifier(n_neighbors=knn_bestNbrs, weights=knn_bestWt)\n",
    "knn.fit(X_train_val_scaled, y_train_val)\n",
    "knn_test = f1_score(y_test, knn.predict(X_test_scaled))\n",
    "\n",
    "#Decision Tree\n",
    "scaler = scalers_dict[dt_bestScaling]\n",
    "scaler.fit(X_train_val)\n",
    "X_train_val_scaled = scaler.transform(X_train_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "dt = DecisionTreeClassifier(max_depth=dt_bestMaxDepth, criterion=dt_bestCrit, random_state=5)\n",
    "dt.fit(X_train_val_scaled, y_train_val)\n",
    "dt_test = f1_score(y_test, dt.predict(X_test_scaled))\n",
    "\n",
    "#SVM\n",
    "scaler = scalers_dict[svm_bestScaling]\n",
    "scaler.fit(X_train_val)\n",
    "X_train_val_scaled = scaler.transform(X_train_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "svc = SVC(C=svm_bestC, kernel=\"rbf\", random_state=5)\n",
    "svc.fit(X_train_val_scaled, y_train_val)\n",
    "svm_test = f1_score(y_test, svc.predict(X_test_scaled))\n",
    "\n",
    "#results\n",
    "print(\"knn best hyperparams:  \", knn_bestNbrs, knn_bestWt, knn_bestScaling)\n",
    "print(\"dt best hyperparams:   \", dt_bestMaxDepth, dt_bestCrit, dt_bestScaling)\n",
    "print(\"svm best hyperparams:  \", svm_bestC, svm_bestScaling)\n",
    "print(\"\\nBest Performance\")\n",
    "print(\"  KNN:  \", knn_test)\n",
    "print(\"  DT:   \", dt_test)\n",
    "print(\"  SVM:  \", svm_test)\n",
    "\n",
    "#sources\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.metrics.f1_score.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html\n",
    "#https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.StratifiedKFold.html\n",
    "#https://datascience.stackexchange.com/questions/102414/i-am-attempting-to-implement-k-folds-cross-validation-in-python3-what-is-the-be"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a288a8af",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p><strong><pre style='display: inline;'>q2</pre></strong> passed! 🎉</p>"
      ],
      "text/plain": [
       "q2 results: All test cases passed!"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grader.check(\"q2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce22db0f-bd37-4ac5-8043-e39d869ae4ac",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q3. Classify Top 10 Hits with Pipelines \n",
    "\n",
    "For this question, you will repeat the analysis from above, but this time you will use pipelines and the `GridSearchCV` method to complete this process. \n",
    "  \n",
    "\n",
    "For each model, you will tune the hyper-parameters:    \n",
    "* KNN, number of neighbors = [5, 9, 13, 17] and weights = ['uniform', 'distance']\n",
    "* Decision Trees, maximum depth of the tree = [3, 5, 8, 12] and criterion of ['gini', 'entropy'], set the random_state = 5\n",
    "* SVM, use a rbf kernel with C = [0.01, 0.1, 1, 10] \n",
    "\n",
    "In addition, you will want to see which scaling methods seems to work best for this dataset and method: `StandardScaler` or `MinMaxScaler`. \n",
    "\n",
    "Overall, you will construct **three pipelines** to perform this analysis one for each model: KNN, DT, SVM.  You will do an initial stratified split of your data into training+validation set with 80% of the data and a test set with 20% of the data (random_state=5).  Use 10-fold stratified cross-validation with a random_state = 5 and shuffle = True. \n",
    "\n",
    "Additionally, when selecting the best hyper-parameters, instead of using accuracy you will use the `f1_measure`.  \n",
    " \n",
    "The steps in your pipeline should be called `scaler` for the scaling step, `knn` for the KNN classifier, `dt` for the Decision Tree, and `svm` for the Support Vector Machine. \n",
    "\n",
    "One note, we are not using the results here to select a certain model (that would be using the test set for more than just estimating the generalized performance), rather just to report out the results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ba2482cf-3e4e-42e0-9e71-c6a35a4e0fc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'knn__n_neighbors': 13, 'knn__weights': 'distance', 'scaler': StandardScaler()}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split of the test set \n",
    "X_trainval, X_test, y_trainval, y_test = train_test_split(\n",
    "    Xm, ym, test_size=0.2, random_state=5, stratify=ym\n",
    ")\n",
    "\n",
    "# ** KNN **\n",
    "# Create pipeline, with steps 'scaler' and 'knn'\n",
    "knn_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"knn\", KNeighborsClassifier())\n",
    "])\n",
    "\n",
    "# specify pipeline steps hyperparameters\n",
    "knn_param = {\n",
    "    \"scaler\": [StandardScaler(), MinMaxScaler()],\n",
    "    \"knn__n_neighbors\": [5, 9, 13, 17],\n",
    "    \"knn__weights\": [\"uniform\", \"distance\"]\n",
    "}\n",
    "\n",
    "# Setup cross-validation for repeatability \n",
    "cvStrat = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "# instantiate and run GridSearchCV on pipeline:\n",
    "knn_grid = GridSearchCV(\n",
    "    knn_pipe,\n",
    "    param_grid=knn_param,\n",
    "    scoring=make_scorer(f1_score, average=\"weighted\"),\n",
    "    cv=cvStrat\n",
    ")\n",
    "knn_grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "# preditions on final test set \n",
    "knn_ytest = knn_grid.predict(X_test)\n",
    "\n",
    "print(knn_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "998f6ff8-9556-4fa9-b454-81da99e36701",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dt__criterion': 'gini', 'dt__max_depth': 8, 'scaler': StandardScaler()}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "np.random.seed(5550)\n",
    "\n",
    "# ** DT ** \n",
    "# Create pipeline, with steps 'scaler' and 'dt'\n",
    "dt_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"dt\", DecisionTreeClassifier(random_state=5))\n",
    "])\n",
    "\n",
    "dt_param = {\n",
    "    \"scaler\": [StandardScaler(), MinMaxScaler()],\n",
    "    \"dt__max_depth\": [3, 5, 8, 12],\n",
    "    \"dt__criterion\": [\"gini\", \"entropy\"]\n",
    "}\n",
    "\n",
    "# Setup cross-validation for repeatability \n",
    "cvStrat = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "# instantiate and run GridSearchCV on pipeline:\n",
    "dt_grid = GridSearchCV(\n",
    "    dt_pipe,\n",
    "    param_grid=dt_param,\n",
    "    scoring=make_scorer(f1_score, average=\"weighted\"),\n",
    "    cv=cvStrat\n",
    ")\n",
    "dt_grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "# preditions on final test set \n",
    "dt_ytest = dt_grid.predict(X_test)\n",
    "\n",
    "\n",
    "print(dt_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d5cb3d-602e-4cd1-8e39-89a1360937a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "# ** SVM ** \n",
    "# Create pipeline, with steps 'scaler' and 'svm'\n",
    "svm_pipe = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),\n",
    "    (\"svm\", SVC(kernel=\"rbf\", random_state=5))\n",
    "])\n",
    "\n",
    "svm_param = {\n",
    "    \"scaler\": [StandardScaler(), MinMaxScaler()],\n",
    "    \"svm__C\": [0.01, 0.1, 1, 10]\n",
    "}\n",
    "\n",
    "# Setup cross-validation for repeatability \n",
    "cvStrat = StratifiedKFold(n_splits=10, shuffle=True, random_state=5)\n",
    "\n",
    "# instantiate and run GridSearchCV on pipeline:\n",
    "svm_grid = GridSearchCV(\n",
    "    svm_pipe,\n",
    "    param_grid=svm_param,\n",
    "    scoring=make_scorer(f1_score, average=\"weighted\"),\n",
    "    cv=cvStrat\n",
    ")\n",
    "svm_grid.fit(X_trainval, y_trainval)\n",
    "\n",
    "# preditions on final test set\n",
    "svm_ytest = svm_grid.predict(X_test)\n",
    "\n",
    "print(svm_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33800952",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "457f03a0-4031-4f3c-8afa-77fff60b77e2",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Q4  Table of Results \n",
    "\n",
    "Report in a DataFrame the following information for each model (use the models from Q3):\n",
    "* `Model` type (KNN, DT, SVM), \n",
    "* best `Hyper-parameters` for the model, e.g., [(n_neighbors, 7), (weights, 'uniform')], (max_depth, 10), ('C', 0.1), etc.\n",
    "* `Accuracy`, \n",
    "* `Precision`,\n",
    "* `Recall`, \n",
    "* `F1-measure` and \n",
    "* `Balanced Acc` - balanced accuracy\n",
    "\n",
    "The last 5 values should all be calculated on the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ce986d-5079-4be6-a371-95623d4e610e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Build data frame of requested results\n",
    "results = pd.DataFrame(columns=[\n",
    "    \"Model\", \"Hyper-parameters\", \"Accuracy\", \"Precision\", \"Recall\", \"F1-measure\", \"Balanced Acc.\"\n",
    "])\n",
    "\n",
    "# Helper function to add results\n",
    "#source https://stackoverflow.com/questions/31421413/how-to-compute-precision-recall-accuracy-and-f1-score-for-the-multiclass-case\n",
    "def add_results_to_table(model_name, best_params, y_true, y_pred):\n",
    "    results.loc[len(results)] = [\n",
    "        model_name, best_params, accuracy_score(y_true, y_pred), precision_score(y_true, y_pred, average=\"weighted\"),\n",
    "        recall_score(y_true, y_pred, average=\"weighted\"), f1_score(y_true, y_pred, average=\"weighted\"), balanced_accuracy_score(y_true, y_pred)\n",
    "    ]\n",
    "\n",
    "#KNN\n",
    "add_results_to_table(\"KNN\", knn_grid.best_params_, y_test, knn_ytest)\n",
    "\n",
    "#Decision Tree\n",
    "add_results_to_table(\"Decision Tree\", dt_grid.best_params_, y_test, dt_ytest)\n",
    "\n",
    "#SVM\n",
    "add_results_to_table(\"SVM\", svm_grid.best_params_, y_test, svm_ytest)\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "764e8a17",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "grader.check(\"q4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80693c1d-41f4-4805-8250-b8a83157d889",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Question 5 \n",
    "\n",
    "Summarize the results.  Write 5-8 sentences about the results observed and the overall performance on the problem.  In particular, call out one of the challenges with this problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52aee96a-e7ba-4a00-b84c-49cf00464baa",
   "metadata": {},
   "source": [
    "* The results indicate that the SVM model outperformed the other two classifiers with the highest accuracy, 0.785; precision, 0.771; recall, 0.785; F1-measure, 0.767; and balanced accuracy, 0.669. This means that the SVM with a MinMaxScaler and C=10 is better at identifying both Top 10 hits and non-hits in a balanced manner. The KNN model with n=13 neighbors and distance-based weights resulted in a slightly lower performance, pointing out the sensitivity of this model to imbalanced data and hyperparameter tuning. Decision Tree, on the other hand, using a maximum depth of 8 and the Gini criterion, has similar precision and recall, though slightly lower balanced accuracy, indicating some issues with properly classifying underrepresented classes.\n",
    "\n",
    "* One challenge in this problem is the inherent imbalance in the dataset, as Top 10 hits are likely underrepresented compared to non-hits. This further affects the model's learning ability and necessitates metrics such as balanced accuracy and weighted F1-scores to show true performance. Moreover, feature scaling was an important preprocessing step for both SVM and KNN, since their algorithms are sensitive to the magnitude of input features. Overall, though models yielded quite good predictive performance, the improvement of class balance and further feature exploration may lead to even better results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1602e6",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "source": [
    "## Submission\n",
    "\n",
    "Make sure you have run all cells in your notebook in order before running the cell below, so that all images/graphs appear in the output. The cell below will generate a zip file for you to submit. **Please save before exporting!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54077d4f",
   "metadata": {
    "deletable": false,
    "editable": false
   },
   "outputs": [],
   "source": [
    "# Save your notebook first, then run this cell to export your submission.\n",
    "grader.export(pdf=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a808b846",
   "metadata": {},
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "otter": {
   "OK_FORMAT": true,
   "assignment_name": "p5",
   "tests": {
    "q1": {
     "name": "q1",
     "points": 1,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> Xm.shape == (4142, 30)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> ym.shape[0] == 4142\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(Xm.columns == ['timesignature', 'loudness', 'tempo', 'key', 'energy', 'pitch', 'timbre_0_min', 'timbre_0_max', 'timbre_1_min', 'timbre_1_max', 'timbre_2_min', 'timbre_2_max', 'timbre_3_min', 'timbre_3_max', 'timbre_4_min', 'timbre_4_max', 'timbre_5_min', 'timbre_5_max', 'timbre_6_min', 'timbre_6_max', 'timbre_7_min', 'timbre_7_max', 'timbre_8_min', 'timbre_8_max', 'timbre_9_min', 'timbre_9_max', 'timbre_10_min', 'timbre_10_max', 'timbre_11_min', 'timbre_11_max'])\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(ym.value_counts() == [3024, 1118])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q2": {
     "name": "q2",
     "points": 11,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> knn_bestNbrs == 5\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q3": {
     "name": "q3",
     "points": 8,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> knn_grid.best_params_['knn__n_neighbors'] == 5\nTrue",
         "hidden": false,
         "locked": false,
         "points": 0.5
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    },
    "q4": {
     "name": "q4",
     "points": 4,
     "suites": [
      {
       "cases": [
        {
         "code": ">>> results.shape == (3, 7)\nTrue",
         "hidden": false,
         "locked": false
        },
        {
         "code": ">>> all(results.columns == ['Model', 'Hyper-parameters', 'Accuracy', 'Precision', 'Recall', 'F1-measure', 'Balanced Acc.'])\nTrue",
         "hidden": false,
         "locked": false
        }
       ],
       "scored": true,
       "setup": "",
       "teardown": "",
       "type": "doctest"
      }
     ]
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
